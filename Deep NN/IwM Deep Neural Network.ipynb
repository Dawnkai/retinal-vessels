{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7fad53c",
   "metadata": {},
   "source": [
    "# Głębokie Sieci Neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dac935",
   "metadata": {},
   "source": [
    "### 1. Wymagane biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5de94509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Określanie lokacji plików\n",
    "import numpy as np # Operacje na macierzach\n",
    "import cv2 # Wczytywanie obrazów\n",
    "import torch # PyTorch\n",
    "import torch.nn as nn # Sieci neuronowe\n",
    "import torch.nn.functional as F # Do specyfikacji funkcji\n",
    "import random # Losowanie liczb\n",
    "import time # Uzyskiwanie obecnego czasu\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate # Morfologia obrazów\n",
    "from torch.utils.data import Dataset # Zbiór danych do uczenia i trenowania\n",
    "from torch.utils.data import DataLoader # Uzyskiwanie obrazu w danej epoce\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score # Wskaźniki jakości modelu\n",
    "from operator import add # Łączenie zdjęć\n",
    "\n",
    "# Obrazy treningowe\n",
    "train_img_path = os.path.abspath('train/images')\n",
    "train_mask_path = os.path.abspath('train/ground_truth')\n",
    "\n",
    "# Obrazy walidacyjne\n",
    "validation_img_path = os.path.abspath('test/images')\n",
    "validation_mask_path = os.path.abspath('test/ground_truth')\n",
    "\n",
    "# Obrazy testowe\n",
    "# Są równoznaczne z walidacyjnymi, ale można to zmienić.\n",
    "# Należy potem wykonać augumentacje na obrazach testowych - tylko do zmiany ich rozmiaru\n",
    "test_img_path = os.path.abspath('test/images')\n",
    "test_mask_path = os.path.abspath('test/ground_truth')\n",
    "\n",
    "# Lokacje zdjęć po augumentacji (zmianie rozmiaru, rotacji, itd)\n",
    "train_augumented_path = os.path.abspath('train/augumented_images')\n",
    "validation_augumented_path = os.path.abspath('test/augumented_images')\n",
    "test_augumented_path = os.path.abspath('test/augumented_images')\n",
    "\n",
    "# Tutaj zostaną zapisane wyniki detekcji modelem siecii\n",
    "results_path = os.path.abspath('results')\n",
    "\n",
    "# Tutaj zostanie zapisany model w trakcie uczenia\n",
    "model_output = os.path.abspath('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ded5cf",
   "metadata": {},
   "source": [
    "### 2. Sieć UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0c7e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(input_size, output_size, kernel_size=3, padding=1)\n",
    "        self.norm_layer1 = nn.BatchNorm2d(output_size)\n",
    "        \n",
    "        self.conv_layer2 = nn.Conv2d(output_size, output_size, kernel_size=3, padding=1)\n",
    "        self.norm_layer2 = nn.BatchNorm2d(output_size)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.conv_layer1(inputs)\n",
    "        x = self.norm_layer1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.norm_layer2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb1788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PullingBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.conv_block = Block(input_size, output_size)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.conv_block(inputs)\n",
    "        p = self.pool(x)\n",
    "        \n",
    "        return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd530a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.d = nn.ConvTranspose2d(input_size, output_size, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv_block = Block(output_size + output_size, output_size)\n",
    "    \n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.d(inputs)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f8b559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.e1 = PullingBlock(3, 64)\n",
    "        self.e2 = PullingBlock(64, 128)\n",
    "        self.e3 = PullingBlock(128, 256)\n",
    "        self.e4 = PullingBlock(256, 512)\n",
    "        \n",
    "        self.b = Block(512, 1024)\n",
    "        \n",
    "        self.d1 = Decoder(1024, 512)\n",
    "        self.d2 = Decoder(512, 256)\n",
    "        self.d3 = Decoder(256, 128)\n",
    "        self.d4 = Decoder(128, 64)\n",
    "        \n",
    "        self.output = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        f1, p1 = self.e1(inputs)\n",
    "        f2, p2 = self.e2(p1)\n",
    "        f3, p3 = self.e3(p2)\n",
    "        f4, p4 = self.e4(p3)\n",
    "        \n",
    "        b = self.b(p4)\n",
    "        \n",
    "        d1 = self.d1(b, f4)\n",
    "        d2 = self.d2(d1, f3)\n",
    "        d3 = self.d3(d2, f2)\n",
    "        d4 = self.d4(d3, f1)\n",
    "        \n",
    "        output = self.output(d4)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f77e58",
   "metadata": {},
   "source": [
    "### 3. Augumentacja obrazu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "318638c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augument_data(img_path, mask_path, output_path, img_size = (512, 512), augument = True):\n",
    "    \"\"\"\n",
    "    Augumentacja obrazu.\n",
    "    :param img_path: - ścieżka do zdjęć na których należy wykonać augumentację\n",
    "    :param mask_path: - ścieżka do mask eksperckich zdjęć z zaznaczonymi żyłami\n",
    "    :param img_size: - docelowy rozmiar obrazów po augumentacji\n",
    "    :param augument: - czy dokonać morfologii obrazów, czy ograniczyć się tylko do zmiany rozmiaru\n",
    "    \"\"\"\n",
    "    # Do wyświetlania postępu augumentacji\n",
    "    num_images = len(os.listdir(img_path))\n",
    "    for idx, image in enumerate(os.listdir(img_path)):\n",
    "        print(f\"Augumenting: {idx} / {num_images}...\")\n",
    "        img = cv2.imread(img_path + '/' + image, cv2.IMREAD_COLOR)\n",
    "        mask = cv2.imread(mask_path + '/' + image.split('.')[0] + '.tif', cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if augument:\n",
    "            h_flip = HorizontalFlip(p=1.0)\n",
    "            v_flip = VerticalFlip(p=1.0)\n",
    "            rotate = Rotate(limit=45, p=1.0)\n",
    "\n",
    "            result1 = h_flip(image=img, mask=mask)\n",
    "            result2 = v_flip(image=img, mask=mask)\n",
    "            result3 = rotate(image=img, mask=mask)\n",
    "\n",
    "            aug_img = cv2.resize(img, img_size)\n",
    "            hflip_img = cv2.resize(result1[\"image\"], img_size)\n",
    "            vflip_img = cv2.resize(result2[\"image\"], img_size)\n",
    "            rotated_img = cv2.resize(result3[\"image\"], img_size)\n",
    "            cv2.imwrite(output_path + '/images/' + image, aug_img)\n",
    "            cv2.imwrite(output_path + '/images/' + image.split('.')[0] + '_hflip.jpg', hflip_img)\n",
    "            cv2.imwrite(output_path + '/images/' + image.split('.')[0] + '_vflip.jpg', vflip_img)\n",
    "            cv2.imwrite(output_path + '/images/' + image.split('.')[0] + '_rotated.jpg', rotated_img)\n",
    "\n",
    "            aug_mask = cv2.resize(mask, img_size)\n",
    "            hflip_mask = cv2.resize(result1[\"mask\"], img_size)\n",
    "            vflip_mask = cv2.resize(result2[\"mask\"], img_size)\n",
    "            rotated_mask = cv2.resize(result3[\"mask\"], img_size)\n",
    "            cv2.imwrite(output_path + '/ground_truth/' + image.split('.')[0] + '.tif', aug_mask)\n",
    "            cv2.imwrite(output_path + '/ground_truth/' + image.split('.')[0] + '_hflip.tif', hflip_mask)\n",
    "            cv2.imwrite(output_path + '/ground_truth/' + image.split('.')[0] + '_vflip.tif', vflip_mask)\n",
    "            cv2.imwrite(output_path + '/ground_truth/' + image.split('.')[0] + '_rotated.tif', rotated_mask)\n",
    "            \n",
    "\n",
    "        else:\n",
    "            augumented_image = cv2.resize(img, img_size)\n",
    "            augumented_mask = cv2.resize(mask, img_size)\n",
    "            cv2.imwrite(output_path + '/images/' + image, augumented_image)\n",
    "            cv2.imwrite(output_path + '/ground_truth/' + image.split('.')[0] + '.tif', augumented_mask)\n",
    "\n",
    "    print(f\"Result images saved to {output_path + '/images'} and masks to {output_path + '/ground_truth'}!\")\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d567e32e",
   "metadata": {},
   "source": [
    "### 4. Model DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dae7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1 - dice\n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "\n",
    "        return Dice_BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cdfadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def srand(seed):\n",
    "    '''\n",
    "    Ustawianie losowych liczb.\n",
    "    :seed: - zmienna na podstawie której ustala się podstawę liczb losowych\n",
    "    '''\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    # Przekaż seed do PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "def get_epoch(start_time, end_time):\n",
    "    '''\n",
    "    Uzyskiwanie czasu, który upłynął między dwoma punktami w czasie.\n",
    "    Do ustalania czasu trwania epoki.\n",
    "    '''\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850f9fbe",
   "metadata": {},
   "source": [
    "### 5. Trenowanie sieci\n",
    "\n",
    "##### 1. Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5b12664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains:\n",
      "120 training images\n",
      "15 validation images\n"
     ]
    }
   ],
   "source": [
    "augument_data(train_img_path, train_mask_path, train_augumented_path)\n",
    "augument_data(validation_img_path, validation_mask_path, validation_augumented_path, augument=False)\n",
    "srand(42)\n",
    "\n",
    "train_images = [f\"{train_augumented_path}/images/{image}\" for image in os.listdir(train_augumented_path + '/images')]\n",
    "train_masks = [f\"{train_augumented_path}/ground_truth/{mask}\" for mask in os.listdir(train_augumented_path + '/ground_truth')]\n",
    "validation_images = [f\"{validation_augumented_path}/images/{image}\" for image in os.listdir(validation_augumented_path + '/images')]\n",
    "validation_masks = [f\"{validation_augumented_path}/ground_truth/{mask}\" for mask in os.listdir(validation_augumented_path + '/ground_truth')]\n",
    "test_images = [f\"{test_augumented_path}/images/{image}\" for image in os.listdir(test_augumented_path + '/images')]\n",
    "test_masks = [f\"{test_augumented_path}/ground_truth/{mask}\" for mask in os.listdir(test_augumented_path + '/ground_truth')]\n",
    "\n",
    "print(f\"Dataset contains:\\n{len(train_images)} training images\\n{len(test_images)} validation images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cd174b",
   "metadata": {},
   "source": [
    "##### 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3d8e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkDataset(Dataset):\n",
    "    def __init__(self, train_img_paths, train_mask_paths):\n",
    "        super().__init__()\n",
    "        self.train_img_paths = train_img_paths\n",
    "        self.train_mask_paths = train_mask_paths\n",
    "        self.num_samples = len(self.train_img_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = cv2.imread(self.train_img_paths[index], cv2.IMREAD_COLOR)\n",
    "        image = image / 255.0\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        image = image.astype(np.float32)\n",
    "        image = torch.from_numpy(image)\n",
    "        \n",
    "        mask = cv2.imread(self.train_mask_paths[index], cv2.IMREAD_GRAYSCALE)\n",
    "        mask = mask / 255.0\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        mask = mask.astype(np.float32)\n",
    "        mask = torch.from_numpy(mask)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccbf801",
   "metadata": {},
   "source": [
    "##### 3. Tworzenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4317f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docelowy rozmiar obrazu podawany do sieci\n",
    "img_size = (512, 512)\n",
    "# Ile obrazów na raz przetwarzać w sieci\n",
    "batch_size = 2\n",
    "# Ile epok ma trwać uczenie\n",
    "num_epochs = 50\n",
    "# Prędkość uczenia sieci\n",
    "learning_rate = 1e-4\n",
    "# Gdzie zapisywać model przy poprawie jakości modelu\n",
    "checkpoint_path = model_output + '/model.pth'\n",
    "\n",
    "# Zbiory danych\n",
    "train_dataset = NetworkDataset(train_images, train_masks)\n",
    "validation_dataset = NetworkDataset(validation_images, validation_masks)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "validation_loader = DataLoader(\n",
    "    dataset=validation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Tworzenie modelu\n",
    "device = torch.device('cuda')\n",
    "model = UNET()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
    "loss_function = DiceBCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be553bc8",
   "metadata": {},
   "source": [
    "##### 4. Uczenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd73752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, loss_function, device):\n",
    "    '''\n",
    "    Algorytm uczenia.\n",
    "    :param model: - model sieci\n",
    "    :param loader: - obiekt wczytujący dane uczące\n",
    "    :param optimizer: - optymalizator\n",
    "    :param loss_function: - funkcja obliczająca błąd, na podstawie którego wyznaczane są wagi\n",
    "    :param device: - urządzenie uczące (gpu lub cpu)\n",
    "    '''\n",
    "    epoch_loss = 0.0\n",
    "    model.train()\n",
    "    for img_tensor, mask_tensor in loader:\n",
    "        img_tensor = img_tensor.to(device, dtype=torch.float32)\n",
    "        mask_tensor = mask_tensor.to(device, dtype=torch.float32)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(img_tensor)\n",
    "        loss = loss_function(prediction, mask_tensor)\n",
    "        # Wsteczna propagacja\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Obliczanie średniego błędu\n",
    "    epoch_loss = epoch_loss / len(loader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf8a973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, loss_function, device):\n",
    "    '''\n",
    "    Ewaluacja jakości modelu na podstawie danych walidacyjnych.\n",
    "    :param model: - model do ewaluacji\n",
    "    :param loader: - obiekt wczytujący dane walidacyjne\n",
    "    :param loss_function: - funkcja błędu pomiaru\n",
    "    :param device: - urządzenie wykonujące walidację (gpu lub cpu)\n",
    "    '''\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for img_tensor, mask_tensor in loader:\n",
    "            img_tensor = img_tensor.to(device, dtype=torch.float32)\n",
    "            mask_tensor = mask_tensor.to(device, dtype=torch.float32)\n",
    "\n",
    "            prediction = model(img_tensor)\n",
    "            loss = loss_function(prediction, mask_tensor)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss = epoch_loss/len(loader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31ee5732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss reduced from inf to 1.0774696543812752, saving model...\n",
      "Epoch: 01 | Epoch Time: 2m 0s\n",
      "\tTrain Loss: 1.156\n",
      "\t Val. Loss: 1.077\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2644/316813016.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtraining_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mvalidation_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2644/1869982295.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, loader, optimizer, loss_function, device)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_loss = float(\"inf\")\n",
    "# Zwalnianie danych w urządzeniu uczącym, zapobiega błędowi CUDA Out of Memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    training_loss = train(model, train_loader, optimizer, loss_function, device)\n",
    "    validation_loss = evaluate(model, validation_loader, loss_function, device)\n",
    "    \n",
    "    # Zapisuj model jeżeli jego jakość się poprawi\n",
    "    if validation_loss < min_loss:\n",
    "        print(f\"Validation loss reduced from {min_loss} to {validation_loss}, saving model...\")\n",
    "        min_loss = validation_loss\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = get_epoch(start_time, end_time)\n",
    "    \n",
    "    # Wypisz dane diagnostyczne\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {validation_loss:.3f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f5c3d",
   "metadata": {},
   "source": [
    "Ponieważ proces uczenia na komputerze lokalnym jest wolny, model został wyuczony na notatniku **Google Colab** i zapisany w folderze `model`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f2239f",
   "metadata": {},
   "source": [
    "### 6. Testowanie sieci\n",
    "\n",
    "##### 1. Wczytywanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45d960d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNET(\n",
       "  (e1): PullingBlock(\n",
       "    (conv_block): Block(\n",
       "      (conv_layer1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_layer2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (e2): PullingBlock(\n",
       "    (conv_block): Block(\n",
       "      (conv_layer1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_layer2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (e3): PullingBlock(\n",
       "    (conv_block): Block(\n",
       "      (conv_layer1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_layer2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (e4): PullingBlock(\n",
       "    (conv_block): Block(\n",
       "      (conv_layer1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_layer2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (b): Block(\n",
       "    (conv_layer1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm_layer1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_layer2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm_layer2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (d1): Decoder(\n",
       "    (d): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv_block): Block(\n",
       "      (conv_layer1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_layer2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (d2): Decoder(\n",
       "    (d): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv_block): Block(\n",
       "      (conv_layer1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_layer2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (d3): Decoder(\n",
       "    (d): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv_block): Block(\n",
       "      (conv_layer1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_layer2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (d4): Decoder(\n",
       "    (d): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv_block): Block(\n",
       "      (conv_layer1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_layer2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm_layer2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (output): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srand(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNET()\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78fc1a8",
   "metadata": {},
   "source": [
    "##### 2. Ewaluacja efektywności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "756d9dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(ground_truth, prediction):\n",
    "    ground_truth = ground_truth.cpu().numpy()\n",
    "    ground_truth = ground_truth > 0.5\n",
    "    ground_truth = ground_truth.astype(np.uint8)\n",
    "    ground_truth = ground_truth.reshape(-1)\n",
    "    \n",
    "    prediction = prediction.cpu().numpy()\n",
    "    prediction = prediction > 0.5\n",
    "    prediction = prediction.astype(np.uint8)\n",
    "    prediction = prediction.reshape(-1)\n",
    "    \n",
    "    jaccard = jaccard_score(ground_truth, prediction)\n",
    "    f1 = f1_score(ground_truth, prediction)\n",
    "    recall = recall_score(ground_truth, prediction)\n",
    "    precision = precision_score(ground_truth, prediction)\n",
    "    acc = accuracy_score(ground_truth, prediction)\n",
    "\n",
    "    return [jaccard, f1, recall, precision, acc]\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a77cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 11_dr.png to C:\\Users\\dawnw\\Desktop\\PP\\IwM\\Projekt 2\\Deep NN\\results...\n",
      "Saving 11_g.png to C:\\Users\\dawnw\\Desktop\\PP\\IwM\\Projekt 2\\Deep NN\\results...\n",
      "Saving 11_h.png to C:\\Users\\dawnw\\Desktop\\PP\\IwM\\Projekt 2\\Deep NN\\results...\n",
      "Saving 12_dr.png to C:\\Users\\dawnw\\Desktop\\PP\\IwM\\Projekt 2\\Deep NN\\results...\n",
      "Saving 12_g.png to C:\\Users\\dawnw\\Desktop\\PP\\IwM\\Projekt 2\\Deep NN\\results...\n",
      "Saving 12_h.png to C:\\Users\\dawnw\\Desktop\\PP\\IwM\\Projekt 2\\Deep NN\\results...\n",
      "Saving 13_dr.png to C:\\Users\\dawnw\\Desktop\\PP\\IwM\\Projekt 2\\Deep NN\\results...\n",
      "Saving 13_g.png to C:\\Users\\dawnw\\Desktop\\PP\\IwM\\Projekt 2\\Deep NN\\results...\n",
      "Saving 13_h.png to C:\\Users\\dawnw\\Desktop\\PP\\IwM\\Projekt 2\\Deep NN\\results...\n",
      "Saving 14_dr.png to C:\\Users\\dawnw\\Desktop\\PP\\IwM\\Projekt 2\\Deep NN\\results...\n",
      "Saving 14_g.png to C:\\Users\\dawnw\\Desktop\\PP\\IwM\\Projekt 2\\Deep NN\\results...\n",
      "Saving 14_h.png to C:\\Users\\dawnw\\Desktop\\PP\\IwM\\Projekt 2\\Deep NN\\results...\n",
      "Saving 15_dr.png to C:\\Users\\dawnw\\Desktop\\PP\\IwM\\Projekt 2\\Deep NN\\results...\n",
      "Saving 15_g.png to C:\\Users\\dawnw\\Desktop\\PP\\IwM\\Projekt 2\\Deep NN\\results...\n",
      "Saving 15_h.png to C:\\Users\\dawnw\\Desktop\\PP\\IwM\\Projekt 2\\Deep NN\\results...\n",
      "Jaccard: 0.6275 - F1: 0.7686 - Recall: 0.6953 - Precision: 0.8663 - Acc: 0.9634\n",
      "FPS:  176.8186749256634\n"
     ]
    }
   ],
   "source": [
    "metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "prediction_times = []\n",
    "\n",
    "for idx, (img, mask) in enumerate(zip([f\"{test_img_path}/{img}\" for img in test_images], [f\"{test_mask_path}/{mask}\" for mask in test_masks])):\n",
    "    result_name = img.split(\"/\")[-1].split(\".\")[0]\n",
    "    \n",
    "    image = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, img_size)\n",
    "    img = np.transpose(image, (2, 0, 1))\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img.astype(np.float32)\n",
    "    img = torch.from_numpy(img)\n",
    "    img = img.to(device)\n",
    "    \n",
    "    expert_mask = cv2.imread(mask, cv2.IMREAD_GRAYSCALE)\n",
    "    expert_mask = cv2.resize(expert_mask, img_size)\n",
    "    mask = np.expand_dims(expert_mask, axis=0)\n",
    "    mask = mask / 255.0\n",
    "    mask = np.expand_dims(expert_mask, axis=0)\n",
    "    mask = mask.astype(np.float32)\n",
    "    mask = torch.from_numpy(mask)\n",
    "    mask = mask.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        prediction = model(img)\n",
    "        prediction = torch.sigmoid(prediction)\n",
    "        elapsed = time.time() - start_time\n",
    "        prediction_times.append(elapsed)\n",
    "        \n",
    "        score = get_score(mask, prediction)\n",
    "        metrics_score = list(map(add, metrics_score, score))\n",
    "        prediction = prediction[0].cpu().numpy()\n",
    "        prediction = np.squeeze(prediction, axis=0)\n",
    "        prediction = prediction > 0.5\n",
    "        prediction = np.array(prediction, dtype=np.uint8)\n",
    "        \n",
    "    expert_mask = mask_parse(expert_mask)\n",
    "    prediction = mask_parse(prediction)\n",
    "    line = np.ones((img_size[1], 10, 3)) * 128\n",
    "    \n",
    "    result = np.concatenate(\n",
    "        [image, line, expert_mask, line, prediction * 255], axis=1\n",
    "    )\n",
    "    print(f\"Saving {result_name}.png to {results_path}...\")\n",
    "    cv2.imwrite(f\"{results_path}/{result_name}.png\", result)\n",
    "\n",
    "mean_jaccard = metrics_score[0]/len(test_images)\n",
    "mean_f1 = metrics_score[1]/len(test_images)\n",
    "mean_recall = metrics_score[2]/len(test_images)\n",
    "mean_precision = metrics_score[3]/len(test_images)\n",
    "mean_acc = metrics_score[4]/len(test_images)\n",
    "print(f\"Jaccard: {mean_jaccard:1.4f} - F1: {mean_f1:1.4f} - Recall: {mean_recall:1.4f} - Precision: {mean_precision:1.4f} - Acc: {mean_acc:1.4f}\")\n",
    "\n",
    "fps = 1/np.mean(prediction_times)\n",
    "print(\"FPS: \", fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd9f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
